get_ipython().getoutput("nvidia-smi")


# Load Git folder
import os
from getpass import getpass
import urllib
repo_user = 'nicolas-dufour'
user = input('Github Username: ')
password = getpass('Password: ')
repo_name = 'time-series-representation-learning'
# your password is converted into url format
password = urllib.parse.quote(password)
cmd_string = 'git clone https://{0}:{1}@github.com/{2}/{3}.git'.format(user, password, repo_user, repo_name)
os.system(cmd_string)
cmd_string, password = "", "" # removing the password from the variable
# Bad password fails silently so make sure the repo was copied
assert os.path.exists(f"/content/{repo_name}"), "Incorrect Password or Repo Not Found, please try again"


get_ipython().run_cell_magic("capture", "", """!pip install git+https://github.com/PyTorchLightning/pytorch-lightning
!pip install wandb""")


get_ipython().run_cell_magic("capture", "", """!wget https://www.cs.ucr.edu/~eamonn/time_series_data_2018/UCRArchive_2018.zip
!unzip -P 'someone' UCRArchive_2018.zip -d /content/time-series-representation-learning/
!mv /content/time-series-representation-learning/UCRArchive_2018 /content/time-series-representation-learning/data
!rm UCRArchive_2018.zip""")


get_ipython().run_line_magic("cd", " /content/time-series-representation-learning/")


get_ipython().run_line_magic("load_ext", " autoreload")
get_ipython().run_line_magic("autoreload", " 2")

import argparse
import json
import os
import sys

import matplotlib.pyplot as plt
import numpy as np
import pandas as pd
import pytorch_lightning as pl
import sklearn
import torch

from datamodule import TimeSeriesDataModule
from loss import TripletLoss
from model import (
    CausalCNN,
    CausalCNNEncoder,
    CausalConvolutionBlock,
    Chomp1d,
    SqueezeChannels,
)
from train import TimeSeriesEmbedder
from utils import load_UCR_dataset

root_data = "./data/"

# The data folder contains the data such that there are:
# ./data/DodgerLoopDay/DodgerLoopDay_TEST.tsv
# ./data/DodgerLoopDay/DodgerLoopDay_TRAIN.tsv


X_train, y_train, X_test, y_test = load_UCR_dataset(root_data, "DodgerLoopDay")

print("X_train: {}".format(X_train.shape))
print("y_train: {}".format(y_train.shape))
print("X_test: {}".format(X_test.shape))
print("y_test: {}".format(y_test.shape))


# Optimization parameters
batch_size = 20
num_workers = 2
betas = (0.9, 0.999)
weight_decay = 1e-2
lr = 0.001

# Model parameter
in_channels = 1
channels = 40
depth = 4
reduced_size = 160
out_channels = 320
kernel_size = 3
N_sample = 288

# Data parameters
train_path = os.path.join(root_data, "FordA", "FordA_TRAIN.tsv")
val_path = os.path.join(root_data, "FordA", "FordA_TEST.tsv")


# Datamodule importation
datamodule = TimeSeriesDataModule(
    train_path,
    val_path,
    batch_size,
    num_workers,
    min_length=20,
    multivariate=False,
    fill_na=True,
)
datamodule.setup()
# Model definition
model = TimeSeriesEmbedder(
    in_channels=in_channels,
    channels=channels,
    depth=depth,
    reduced_size=reduced_size,
    out_channels=out_channels,
    kernel_size=kernel_size,
    lr=lr,
    weight_decay=weight_decay,
    betas=betas,
)


max_steps = 2000
checkpoint_callback = pl.callbacks.ModelCheckpoint(
    mode="min",
    monitor="train_loss_epoch",
    dirpath="checkpoints",
    filename="causalcnn-{epoch:02d}-{train_loss_epoch:.2f}",
)

wandb_logger = pl.loggers.WandbLogger(
    project="Self Supervised Time Series LEarning", name="Run n 1"
)
trainer = pl.Trainer(
    gpus=1,
    max_steps=max_steps,
    num_sanity_val_steps = -1,
    logger=wandb_logger,
    # val_check_interval=50,
    callbacks=[checkpoint_callback],
)


trainer.fit(model, datamodule)


trainer.validate(model)


trainer.test()


import plotly.express as px

px.scatter(
    model.val_tsne_rep, x="x", y="y", color="labels", animation_frame="step"
)


trainer.test()


# Load the data
from pyts.datasets import load_basic_motions, uea_dataset_list

X_train, X_test, y_train, y_test = load_basic_motions(return_X_y=True)


# Preprocessing: normalization
X_train = (X_train - X_train.mean(axis=2)[:, :, None]) / X_train.std(axis=2)[:, :, None]
X_test = (X_test - X_test.mean(axis=2)[:, :, None]) / X_test.std(axis=2)[:, :, None]


X_train = torch.from_numpy(X_train).double()
X_test = torch.from_numpy(X_test).double()
if torch.cuda.is_available():
    X_train = X_train.cuda()
    X_test = X_test.cuda()


labels = [
    "Accelerometer - X",
    "Accelerometer - Y",
    "Accelerometer - Z",
    "Gyroscope - Yaw",
    "Gyroscope - Pitch",
    "Gyroscope - Roll",
]
if True:
    index = 0
    fig = plt.figure(figsize=(30, 15))
    axes = []
    for i in range(6):
        axes.append(fig.add_subplot(6, 2, 2 * i + 1))
        axes[i].set_title(
            "{}".format(str(y_train[index])[2:-1]), weight="bold", fontsize=18
        )
        axes[i].plot(X_train[index, i, :], label=labels[i])
        axes[i].legend(loc=1)
    index = -1
    for i in range(6):
        axes.append(fig.add_subplot(6, 2, 2 * (i + 1)))
        axes[6 + i].set_title(
            "{}".format(str(y_train[index])[2:-1]), weight="bold", fontsize=18
        )
        axes[6 + i].plot(X_train[index, i, :], label=labels[i])
        axes[6 + i].legend(loc=1)
plt.tight_layout()


in_channels = 6
channels = 40
depth = 4
reduced_size = 160
out_channels = 320
kernel_size = 3
N_sample = 100

# The whole model
causalEncoder = CausalCNNEncoder(
    in_channels=in_channels,
    channels=channels,
    depth=depth,
    reduced_size=reduced_size,
    out_channels=out_channels,
    kernel_size=kernel_size,
).double()

# The whole model without the last global average pooling and FC between reduced_size and out_channel
causal_cnn = CausalCNN(
    in_channels=in_channels,
    channels=channels,
    depth=depth,
    out_channels=out_channels,
    kernel_size=kernel_size,
).double()


##### BUILDING EACH BLOCK OF THE MODEL

# Each of the Causal CNN Blocks (of width 4)
ConvBlock_1 = CausalConvolutionBlock(
    in_channels=in_channels, out_channels=channels, dilation=1, kernel_size=3
).double()
ConvBlock_2 = CausalConvolutionBlock(
    in_channels=channels, out_channels=channels, dilation=2, kernel_size=3
).double()
ConvBlock_3 = CausalConvolutionBlock(
    in_channels=channels, out_channels=channels, dilation=4, kernel_size=3
).double()
ConvBlock_4 = CausalConvolutionBlock(
    in_channels=channels, out_channels=reduced_size, dilation=8, kernel_size=3
).double()

# Global average pooling
reduce_size = torch.nn.AdaptiveMaxPool1d(1)

# Squeez the last (third) temporal dimension
squeeze = SqueezeChannels()

# last fully connected layer to go from reduced_size to out_channel
linear = torch.nn.Linear(reduced_size, out_channels).double()


model_from_scratch = [
    ConvBlock_1,
    ConvBlock_2,
    ConvBlock_3,
    ConvBlock_4,
    reduce_size,
    squeeze,
    linear,
]
model_name_from_scratch = [
    "ConvBlock_1",
    "ConvBlock_2",
    "ConvBlock_3",
    "ConvBlock_4",
    "Global Average Pooling",
    "squeezing",
    "final FC",
]

print("Input Shape:")
print(list(X_train.shape), "\n")
input = X_train
for block_ii in range(len(model_from_scratch)):
    print("{}:".format(model_name_from_scratch[block_ii]))
    output = model_from_scratch[block_ii](input)
    print(list(output.shape), "\n")
    input = output


# Instead of the Global Average Pooling
linear_to_squeeze = torch.nn.Linear(N_sample, 1).double()


model_from_scratch_experiment = [
    ConvBlock_1,
    ConvBlock_2,
    ConvBlock_3,
    ConvBlock_4,
    linear_to_squeeze,
    squeeze,
    linear,
]
model_name_from_scratch_experiment = [
    "ConvBlock_1",
    "ConvBlock_2",
    "ConvBlock_3",
    "ConvBlock_4",
    "linear_to_squeeze",
    "squeezing",
    "final FC",
]

print("Input Shape:")
print(list(X_train.shape), "\n")
input = X_train
for block_ii in range(len(model_from_scratch_experiment)):
    print("{}:".format(model_name_from_scratch_experiment[block_ii]))
    output = model_from_scratch_experiment[block_ii](input)
    print(list(output.shape), "\n")
    input = output





# Save to git
get_ipython().getoutput("git config --global user.email "nicolas.dufourn@gmail.com"")
get_ipython().getoutput("git config --global user.name "Nicolas DUFOUR"")
get_ipython().getoutput("git add --all")
get_ipython().getoutput("git commit -m "Fixed val logging"")
get_ipython().getoutput("git push")


get_ipython().run_line_magic("ls", "")



